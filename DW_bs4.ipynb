{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "covered-lending",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re \n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen\n",
    "from urllib.parse import urljoin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ethical-saint",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary of doctors: key is the Doctor \"name\" from the site we scrape, value - his/her number\n",
    "doctors = {\n",
    "        'Jodie Whittaker':13,\n",
    "        'Twelfth Doctor':12,\n",
    "        'Seventh Doctor':7,\n",
    "        'First Doctor':1,\n",
    "        'Second Doctor':2,\n",
    "        'Eleventh Doctor':11,\n",
    "        'Third Doctor':3,\n",
    "        'Fourth Doctor':4,\n",
    "        'Eighth Doctor':8,\n",
    "        'Tenth Doctor':10,\n",
    "        'Sixth Doctor':6,\n",
    "        'Fifth Doctor':4,\n",
    "        'Ninth Doctor':9\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "labeled-family",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This function gets the link and splits it\n",
    "Examples:\n",
    "\n",
    "1-0.html    -> 1, 0. 0\n",
    "1-1-1.html  -> 1, 1, 1\n",
    "A.html      -> 0, 0, 0\n",
    "\n",
    "The numeric episodes are required in order to sort the dataset by the appearence of episodes.\n",
    "It is critical for dataset built with scrapy because scrapy crawls the link asynchroniously\n",
    "\n",
    "'''\n",
    "\n",
    "def get_episode(episode_link):\n",
    "    splitted = re.split('[-|.]', episode_link)\n",
    "    if len(splitted) == 2:\n",
    "        return (0, 0, 0)\n",
    "    elif len(splitted) == 4:\n",
    "        return (int(splitted[0]), int(splitted[1]), int(splitted[2]))\n",
    "    else:\n",
    "        return (int(splitted[0]), int(splitted[1]), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "anticipated-implementation",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This function gets the text separated by new line and sequuentally builds a dataset from it in he following way:\n",
    "1. Marks and enumerates parts and scenese by id and name\n",
    "2. Tags If the sentence is a talk, context or location\n",
    "3. Splits the talk sentences into \"talker\" and \"talk\" iself\n",
    "\n",
    "Part_id and part_name are required for marking teh scripts devided into parts or episodes\n",
    "Example\n",
    "\n",
    "(narrative)\n",
    "[Tardis]\n",
    "DOCTOR: Hello, Dalek\n",
    "DALEK: EXTERMINATE\n",
    "\n",
    "'part_id', 'part_name', 'scene_id','scene_name', 'text',        'phrase_type', 'detail'\n",
    " 0          ''           0          0             narrative      context       NaN\n",
    " 0          ''           1          Tardis        NaN            location      NaN\n",
    " 0          ''           1          Tardis        Hello, Dalek   talk          DOCTOR\n",
    " 0          ''           1          Tardis        EXTERMINATE    talk          DALEK \n",
    "\n",
    "'''\n",
    "def parse_lines(lines):\n",
    "    details = ''\n",
    "    phrase_type = 'talk'\n",
    "    scene_id = 0\n",
    "    scene_name = ''\n",
    "    text = ''\n",
    "    part_id=0\n",
    "    part_name = ''\n",
    "    results = []\n",
    "    for line in lines:\n",
    "        #scene (location) is found\n",
    "        if line.startswith('['):\n",
    "            scene_id += 1\n",
    "            scene_name = line.replace('\\n',' ').strip()\n",
    "            details = ''\n",
    "            text = ''\n",
    "            phrase_type = 'location'\n",
    "        #context is found    \n",
    "        elif line.startswith('('):\n",
    "            details = ''\n",
    "            text = line.replace('\\n',' ').strip()   \n",
    "            phrase_type = 'context'\n",
    "        #talk is found\n",
    "        elif len(re.findall(\"[A-Z]*: \", line)) > 0:\n",
    "            sent = re.split(r\"([A-Z]*: )\", line)\n",
    "            details = sent[1].split(':')[0].strip()\n",
    "            text = sent[2].strip()\n",
    "            phrase_type = 'talk'\n",
    "        #back link is found (to handle some xpth problem, relevant for scrapy)   \n",
    "        elif line.startswith('<Back'):\n",
    "            break\n",
    "        #episode or part is found    \n",
    "        elif line.startswith('Episode') or line.startswith('Part'):\n",
    "            #print(line)\n",
    "            part_id+=1\n",
    "            part_name = line.replace('\\n',' ').strip()        \n",
    "            details = ''\n",
    "            text = ''\n",
    "            phrase_type = 'episode'\n",
    "        #handle current line as it belongs to previously found type    \n",
    "        else:\n",
    "            text = line.replace('\\n',' ').strip()   \n",
    "        results.append([part_id,part_name,scene_id, scene_name, text, phrase_type,details])\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "piano-coach",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_url = 'http://www.chakoteya.net/DoctorWho/'\n",
    "#gets request from url\n",
    "req = urlopen(start_url)\n",
    "#builds sup object based on the results, 'html5lib' is used because it knows how to handle unmatched html taks\n",
    "soup = BeautifulSoup(req, 'html5lib')\n",
    "results = []\n",
    "#handle main page\n",
    "#get all a tags\n",
    "all_l = soup.find_all('a')\n",
    "counter = 0\n",
    "for a in all_l:    \n",
    "    if counter == 13:\n",
    "        break\n",
    "    #try fetch image from the a tag: we are in terested only in <a href=....><img/></a>    \n",
    "    img = a.find('img')    \n",
    "    if img is not None:\n",
    "        counter +=1\n",
    "        #extract link\n",
    "        link = a.attrs['href']\n",
    "        #extract text\n",
    "        doctor_name = img.attrs['alt']\n",
    "        #get Doctor's id by name\n",
    "        doctor_id = doctors[doctor_name]\n",
    "        #scrape the content of the found link:\n",
    "        #build url\n",
    "        full_url = urljoin(start_url,link)        \n",
    "        req = urlopen(full_url)\n",
    "        #build new soup object\n",
    "        soup = BeautifulSoup(req, 'html5lib')\n",
    "        #get the table with border=\"1\" - it is a table that contains a list of episodes\n",
    "        tables = soup.find_all('table',{\"border\": \"1\"})        \n",
    "        #fetch all rows\n",
    "        trs = tables[0].find_all('tr')\n",
    "        #for each ror\n",
    "        for tr in trs:\n",
    "            #find all cells\n",
    "            tds = tr.find_all('td')\n",
    "            if len(tds)==3:\n",
    "                #if the cell belongs to the body of the table (e can cehck it by bgcolor attribute) \n",
    "                #and contains link to the scripts\n",
    "                if tds[0].attrs['bgcolor']!='#006b9f' and len(tds[0].find_all('a'))>0 :                    \n",
    "                    #get link\n",
    "                    episode_link = tds[0].find_all('a')[0].attrs['href']\n",
    "                    #get episodes' name\n",
    "                    episode_name = tds[0].find_all('a')[0].text\n",
    "                    #parse link to get season and episodes ids\n",
    "                    ord_season_id, episode_id_1, episode_id_2 = get_episode(episode_link)\n",
    "                    #build url to the scripts page\n",
    "                    full_url = urljoin(full_url,episode_link)                    \n",
    "                    req = urlopen(full_url)\n",
    "                    #get new soup object\n",
    "                    soup = BeautifulSoup(req, 'html5lib')                    \n",
    "                    td = soup.find_all('td')[0]          \n",
    "                    #find td element - it is single in the page\n",
    "                    #soup = BeautifulSoup(td.text, 'html5lib')\n",
    "                    #clean all tags and styles, so we ge a list of plain texts\n",
    "                    for script in td(['script','style']):\n",
    "                        script.decompose()  # rip it out                   \n",
    "                    #process the list of sentences to build the features we need    \n",
    "                    processed_text = parse_lines(td.stripped_strings)           \n",
    "                    #for each feature set build a record fopr our future dataset\n",
    "                    for record in processed_text:\n",
    "                        results.append([doctor_name,doctor_id,episode_name, episode_link.split('.')[0],\n",
    "                                ord_season_id,episode_id_1,episode_id_2,\n",
    "                                record[0],record[1],record[2],record[3],record[4],\n",
    "                                record[5],record[6]])     \n",
    "                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "controversial-memorial",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "331896"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "stable-shelf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "331896"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#len(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "empirical-characteristic",
   "metadata": {},
   "outputs": [],
   "source": [
    "#build the final dataset                        \n",
    "ds = pd.DataFrame(results,columns=['doctor_name', 'doctor_id', 'episode_name', 'episodid','ord_season_id',\n",
    "       'episode_id_1', 'episode_id_2', 'part_id', 'part_name', 'scene_id',\n",
    "       'scene_name', 'text', 'phrase_type', 'detail'])     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "capital-phone",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doctor_name</th>\n",
       "      <th>doctor_id</th>\n",
       "      <th>episode_name</th>\n",
       "      <th>episodid</th>\n",
       "      <th>ord_season_id</th>\n",
       "      <th>episode_id_1</th>\n",
       "      <th>episode_id_2</th>\n",
       "      <th>part_id</th>\n",
       "      <th>part_name</th>\n",
       "      <th>scene_id</th>\n",
       "      <th>scene_name</th>\n",
       "      <th>text</th>\n",
       "      <th>phrase_type</th>\n",
       "      <th>detail</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>First Doctor</td>\n",
       "      <td>1</td>\n",
       "      <td>Pilot - An Unearthly Child</td>\n",
       "      <td>1-0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>[Scrap Yard]</td>\n",
       "      <td></td>\n",
       "      <td>location</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>First Doctor</td>\n",
       "      <td>1</td>\n",
       "      <td>Pilot - An Unearthly Child</td>\n",
       "      <td>1-0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>[Scrap Yard]</td>\n",
       "      <td>(Night, a policeman is patrolling his beat pas...</td>\n",
       "      <td>context</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>First Doctor</td>\n",
       "      <td>1</td>\n",
       "      <td>Pilot - An Unearthly Child</td>\n",
       "      <td>1-0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td>[School]</td>\n",
       "      <td></td>\n",
       "      <td>location</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>First Doctor</td>\n",
       "      <td>1</td>\n",
       "      <td>Pilot - An Unearthly Child</td>\n",
       "      <td>1-0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td>[School]</td>\n",
       "      <td>(The bell is ringing for end of classes)</td>\n",
       "      <td>context</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>First Doctor</td>\n",
       "      <td>1</td>\n",
       "      <td>Pilot - An Unearthly Child</td>\n",
       "      <td>1-0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td>[School]</td>\n",
       "      <td>Wait in here please, Susan. I won't be long.</td>\n",
       "      <td>talk</td>\n",
       "      <td>BARBARA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    doctor_name  doctor_id                episode_name episodid  \\\n",
       "0  First Doctor          1  Pilot - An Unearthly Child      1-0   \n",
       "1  First Doctor          1  Pilot - An Unearthly Child      1-0   \n",
       "2  First Doctor          1  Pilot - An Unearthly Child      1-0   \n",
       "3  First Doctor          1  Pilot - An Unearthly Child      1-0   \n",
       "4  First Doctor          1  Pilot - An Unearthly Child      1-0   \n",
       "\n",
       "   ord_season_id  episode_id_1  episode_id_2  part_id part_name  scene_id  \\\n",
       "0              1             0             0        0                   1   \n",
       "1              1             0             0        0                   1   \n",
       "2              1             0             0        0                   2   \n",
       "3              1             0             0        0                   2   \n",
       "4              1             0             0        0                   2   \n",
       "\n",
       "     scene_name                                               text  \\\n",
       "0  [Scrap Yard]                                                      \n",
       "1  [Scrap Yard]  (Night, a policeman is patrolling his beat pas...   \n",
       "2      [School]                                                      \n",
       "3      [School]           (The bell is ringing for end of classes)   \n",
       "4      [School]       Wait in here please, Susan. I won't be long.   \n",
       "\n",
       "  phrase_type   detail  \n",
       "0    location           \n",
       "1     context           \n",
       "2    location           \n",
       "3     context           \n",
       "4        talk  BARBARA  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "empirical-construction",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ds[(ds['doctor_id']==1) & (ds['ord_season_id']==\"3\")] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "exciting-manner",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 331896 entries, 0 to 331895\n",
      "Data columns (total 14 columns):\n",
      " #   Column         Non-Null Count   Dtype \n",
      "---  ------         --------------   ----- \n",
      " 0   doctor_name    331896 non-null  object\n",
      " 1   doctor_id      331896 non-null  int64 \n",
      " 2   episode_name   331896 non-null  object\n",
      " 3   episodid       331896 non-null  object\n",
      " 4   ord_season_id  331896 non-null  int64 \n",
      " 5   episode_id_1   331896 non-null  int64 \n",
      " 6   episode_id_2   331896 non-null  int64 \n",
      " 7   part_id        331896 non-null  int64 \n",
      " 8   part_name      331896 non-null  object\n",
      " 9   scene_id       331896 non-null  int64 \n",
      " 10  scene_name     331896 non-null  object\n",
      " 11  text           331896 non-null  object\n",
      " 12  phrase_type    331896 non-null  object\n",
      " 13  detail         331896 non-null  object\n",
      "dtypes: int64(6), object(8)\n",
      "memory usage: 35.5+ MB\n"
     ]
    }
   ],
   "source": [
    "ds.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "photographic-violation",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-nlg] *",
   "language": "python",
   "name": "conda-env-.conda-nlg-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
